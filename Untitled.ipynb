{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.cross_validation\n",
    "import sklearn.svm\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.neighbors\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk.sentiment\n",
    "import pickle\n",
    "negate_list = [\"not\",\"never\",\"no\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"../dataset/positive-words.txt\")\n",
    "positive = file.readlines()\n",
    "positive_set = set()\n",
    "for i in range(len(positive)):\n",
    "    positive_set.add(positive[i][:-2])\n",
    "    positive_set.add(positive[i][:-2]+\"_NEG\")\n",
    "file = open(\"../dataset/negative-words.txt\")\n",
    "negative = file.readlines()\n",
    "negative_set = set()\n",
    "for i in range(len(positive)):\n",
    "    negative_set.add(positive[i][:-2])\n",
    "    negative_set.add(positive[i][:-2]+\"_NEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_adj(documents):\n",
    "    new_docs = []\n",
    "    for doc in documents:\n",
    "        doc = doc.lower()\n",
    "        new_words = []\n",
    "        words = doc.split()\n",
    "        for word in words:\n",
    "            new_words.append(word)\n",
    "            if word in positive_set or word in negative_set:\n",
    "                new_words.append(word)\n",
    "                new_words.append(word)\n",
    "        new_doc = ' '.join(new_words)\n",
    "        new_docs.append(new_doc)\n",
    "    return new_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/saket/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/saket/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/saket/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "en_stop = set(stopwords.words('english'))\n",
    "p_stemmer = PorterStemmer()\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "train_pickle = \"lemmed_doc.pkl\"\n",
    "test_pickle = \"lemmed_dev.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measures(class_labels,predicted_class):\n",
    "    print \"accuracy\",sklearn.metrics.accuracy_score(class_labels,predicted_class)\n",
    "    print \"confusion\"\n",
    "    confusion = sklearn.metrics.confusion_matrix(class_labels,predicted_class)\n",
    "    print confusion\n",
    "    print \"macro f\",sklearn.metrics.f1_score(class_labels,predicted_class,average='macro')\n",
    "    print \"micro f\",sklearn.metrics.f1_score(class_labels,predicted_class,average='micro')\n",
    "    print \"weighted f\",sklearn.metrics.f1_score(class_labels,predicted_class,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(docs,adjective):\n",
    "    new_docs = []\n",
    "    for document in docs:\n",
    "        raw = document.lower()\n",
    "        raw = raw.replace(\"<br /><br />\", \" \")\n",
    "        tokens = tokenizer.tokenize(raw)\n",
    "        if adjective:\n",
    "            pos = nltk.pos_tag(tokens)\n",
    "            adj_list = [tag[0] for tag in pos if tag[1] == 'JJ']\n",
    "        stopped_tokens = [token for token in tokens if token not in en_stop]\n",
    "        stemmed_tokens = [p_stemmer.stem(token) for token in stopped_tokens]\n",
    "        if adjective:\n",
    "            stemmed_adj_tokens = [p_stemmer.stem(token) for token in adj_list]\n",
    "            stemmed_tokens = stemmed_tokens + stemmed_adj_tokens\n",
    "        documentWords = ' '.join(stemmed_tokens)\n",
    "        new_docs.append(documentWords)\n",
    "    return new_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning2(docs):\n",
    "    new_docs = []\n",
    "    for document in docs:\n",
    "        raw = document.lower()\n",
    "        raw = raw.replace(\"<br /><br />\", \" \")\n",
    "        tokens = tokenizer.tokenize(raw)\n",
    "        stopped_tokens = [token for token in tokens if token not in en_stop]\n",
    "        documentWords = ' '.join(stopped_tokens)\n",
    "        new_docs.append(documentWords)\n",
    "    return new_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_clear(tokens):\n",
    "    i =0\n",
    "    for token in tokens:\n",
    "        if token in negate_list or token[-3:]==\"n't\":\n",
    "            if i+1 < len(tokens):\n",
    "                tokens[i+1] =  tokens[i+1] + \"_NEG\"\n",
    "            if i+2 < len(tokens):\n",
    "                tokens[i+2] = tokens[i+2] + \"_NEG\"\n",
    "        i+=1\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negate(documents):\n",
    "    new_documents = []\n",
    "    for doc in documents:\n",
    "#         doc = doc.lower()\n",
    "        words = doc.split()\n",
    "        new_words = not_clear(words)\n",
    "        newdocument = ' '.join(new_words)\n",
    "        new_documents.append(newdocument)\n",
    "    return new_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../dataset/audio_train.json' \n",
    "documents = []\n",
    "class_labels = []\n",
    "summary = []\n",
    "\n",
    "with open(filepath,'r') as fp:  \n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        input_data = (json.loads(line))\n",
    "        documents.append(input_data[\"reviewText\"])\n",
    "        summary.append(input_data[\"summary\"])\n",
    "        class_label = float(input_data[\"overall\"])\n",
    "        if class_label==1:\n",
    "            class_labels.append(-2)\n",
    "        elif class_label==2:\n",
    "            class_labels.append(-1)\n",
    "        elif class_label==3:\n",
    "            class_labels.append(0)\n",
    "        elif class_label==4:\n",
    "            class_labels.append(1)\n",
    "        else:\n",
    "            class_labels.append(2)\n",
    "        line = fp.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_documents = []\n",
    "dev_labels = []\n",
    "filepath = '../dataset/audio_dev.json' \n",
    "dev_summary = []\n",
    "with open(filepath,'r') as fp:  \n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        input_data = (json.loads(line))\n",
    "        class_label = float(input_data[\"overall\"])\n",
    "        dev_summary.append(input_data[\"summary\"])\n",
    "        if class_label<=2:\n",
    "            dev_documents.append(input_data[\"reviewText\"])\n",
    "            dev_labels.append(-1)\n",
    "        elif class_label==3:\n",
    "            dev_documents.append(input_data[\"reviewText\"])\n",
    "            dev_labels.append(0)\n",
    "        else:\n",
    "            dev_documents.append(input_data[\"reviewText\"])\n",
    "            dev_labels.append(1)\n",
    "        line = fp.readline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def under_sample(sample_size,documents,labels,summary):\n",
    "    counter_1 = 0\n",
    "    counter_2 = 0\n",
    "    counter_3 = 0\n",
    "    undersampled_docs = []\n",
    "    undersampled_labels = []\n",
    "    undersampled_summary = []\n",
    "    i = 0\n",
    "    for i in range(len(documents)):\n",
    "        if labels[i]==-1 and counter_1 < sample_size:\n",
    "            undersampled_docs.append(documents[i])\n",
    "            undersampled_labels.append(labels[i])\n",
    "            undersampled_summary.append(summary[i])\n",
    "            counter_1 += 1\n",
    "        elif labels[i]==0 and counter_2 < sample_size:\n",
    "            undersampled_docs.append(documents[i])\n",
    "            undersampled_labels.append(labels[i])\n",
    "            undersampled_summary.append(summary[i])\n",
    "            counter_2 += 1\n",
    "        elif labels[i]==1 and counter_3 < sample_size:\n",
    "            undersampled_docs.append(documents[i])\n",
    "            undersampled_labels.append(labels[i])\n",
    "            undersampled_summary.append(summary[i])\n",
    "            counter_3 += 1\n",
    "        if counter_1 == sample_size and counter_2 == sample_size and counter_3 == sample_size:\n",
    "            break\n",
    "    return undersampled_docs,undersampled_labels,undersampled_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_particular(label,documents,labels,summary):\n",
    "    undersampled_docs = []\n",
    "    undersampled_labels = []\n",
    "    undersampled_summary = []\n",
    "    i = 0\n",
    "    for i in range(len(documents)):\n",
    "        if labels[i] == label:\n",
    "            undersampled_docs.append(documents[i] + summary[i] + summary[i] + summary[i])\n",
    "            undersampled_labels.append(labels[i])\n",
    "            undersampled_summary.append(summary[i])\n",
    "    return undersampled_docs,undersampled_labels,undersampled_summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37068\n",
      "37118\n",
      "81649\n",
      "196969\n",
      "525270\n"
     ]
    }
   ],
   "source": [
    "# undersampled_docs3,undersampled_labels3,undersampled_summary3 = under_sample(74000,documents,class_labels,summary)\n",
    "\n",
    "# # undersampled_summary = cleaning(summary,0)\n",
    "# with open('../pickles/complete_summary.pkl', 'rb') as f:\n",
    "#     cleaned_summary = pickle.load(f)\n",
    "\n",
    "# with open('../pickles/undersampled_clean.pkl', 'rb') as f:\n",
    "#     undersampled_docs3 = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# with open('../pickles/complete_train_300000_clean.pkl', 'rb') as f:\n",
    "#     undersampled_docs1 = pickle.load(f)\n",
    "# with open('../pickles/complete_train_800000_clean.pkl', 'rb') as f:\n",
    "#     undersampled_docs2 = pickle.load(f)\n",
    "# cleaned_documents = undersampled_docs1 + undersampled_docs2\n",
    "# undersampled_docs1,undersampled_labels1,undersampled_summary1 = get_particular(-1,cleaned_documents,class_labels,summary)\n",
    "# undersampled_docs3,undersampled_labels3,undersampled_summary3 = get_particular(1,cleaned_documents,class_labels,summary)\n",
    "\n",
    "# undersampled_docs = undersampled_docs1 + undersampled_docs2 + undersampled_docs2[0:20000] +undersampled_docs3[0:200000]\n",
    "# undersampled_labels = undersampled_labels1 + undersampled_labels2 + undersampled_docs2[0:20000] + undersampled_labels3[0:200000]\n",
    "\n",
    "# undersampled_docs = negate(documents)\n",
    "# undersampled_labels = class_labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# with open('../pickles/complete_train_300000_clean.pkl', 'rb') as f:\n",
    "#     undersampled_docs1 = pickle.load(f)\n",
    "# with open('../pickles/complete_train_800000_clean.pkl', 'rb') as f:\n",
    "#     undersampled_docs2 = pickle.load(f)\n",
    "# with open('../dataset/summary.pkl','rb') as f:\n",
    "#     undersampled_summary = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "# undersampled_docs1,undersampled_labels1,undersampled_summary1 = get_particular(-1,documents,class_labels,summary)\n",
    "# undersampled_docs2,undersampled_labels2,undersampled_summary2 = get_particular(0,documents,class_labels,summary)\n",
    "# undersampled_docs = documents\n",
    "# print len(undersampled_summary)\n",
    "\n",
    "# for i in range(len(undersampled_docs)):\n",
    "#     undersampled_docs[i] = undersampled_docs[i] + summary[i] + summary[i] + summary[i]\n",
    "\n",
    "undersampled_docs1,undersampled_labels1,undersampled_summary1 = get_particular(-2,documents,class_labels,summary)\n",
    "undersampled_docs2,undersampled_labels2,undersampled_summary2 = get_particular(-1,documents,class_labels,summary)\n",
    "undersampled_docs3,undersampled_labels3,undersampled_summary3 = get_particular(0,documents,class_labels,summary)\n",
    "undersampled_docs4,undersampled_labels4,undersampled_summary4 = get_particular(1,documents,class_labels,summary)\n",
    "undersampled_docs5,undersampled_labels5,undersampled_summary5 = get_particular(2,documents,class_labels,summary)\n",
    "print len(undersampled_docs1)\n",
    "print len(undersampled_docs2)\n",
    "print len(undersampled_docs3)\n",
    "print len(undersampled_docs4)\n",
    "print len(undersampled_docs5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505835\n"
     ]
    }
   ],
   "source": [
    "undersampled_docs = undersampled_docs1[0:20000] + undersampled_docs2[0:20000] + undersampled_docs3[0:40000] + undersampled_docs4[0:50000] + undersampled_docs5[0:50000]\n",
    "undersampled_labels = undersampled_labels1[0:20000] + undersampled_labels2[0:20000] + undersampled_labels3[0:40000] + undersampled_labels4[0:50000] + undersampled_labels5[0:50000]\n",
    "\n",
    "\n",
    "undersampled_docs = negate(undersampled_docs)\n",
    "undersampled_docs = cleaning2(undersampled_docs)\n",
    "undersampled_docs = add_adj(undersampled_docs)\n",
    "# undersampled_labels = class_labels\n",
    "\n",
    "\n",
    "# for i in range(len(undersampled_docs)):\n",
    "#     undersampled_docs[i] = undersampled_docs[i] + undersampled_summary[i] + undersampled_summary[i]\n",
    "\n",
    "# undersampled_docs = documents\n",
    "# undersampled_labels = class_labels \n",
    "print len(undersampled_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "despite big rush fan could take_neg this_neg album like like like modern modern modern day alternative music would like like like album yes true rush always evolved evolve better better better rest music world thats standard rush set far concerned anything less acceptable _neg no_neg matter old neil pert lost family think geddy lee explored tempo music like like like demonstrated favorite favorite favorite headache words listening_neg to_neg vapor trails already given couple tries sorry offend wish released_neg this_neg album wish released_neg this_neg album wish released_neg this_neg album\n"
     ]
    }
   ],
   "source": [
    "print undersampled_docs[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dev_documents = cleaning(dev_documents[0:10000],0)\n",
    "# dev_documents = dev_documents[0:10000]\n",
    "\n",
    "# with open('../pickles/complete_dev_clean.pkl', 'rb') as f:\n",
    "#     udev_documents = pickle.load(f)\n",
    "# with open('../dataset/dev_summary.pkl', 'rb') as f:\n",
    "#     udev_summary = pickle.load(f)\n",
    "\n",
    "udev_documents = dev_documents\n",
    "for i in range(len(udev_documents)):\n",
    "    udev_documents[i] = udev_documents[i] + dev_summary[i] + dev_summary[i] + dev_summary[i]\n",
    "\n",
    "udev_documents = negate(udev_documents)\n",
    "udev_documents = cleaning2(udev_documents)\n",
    "udev_labels = dev_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_vect = sklearn.feature_extraction.text.TfidfVectorizer(token_pattern=r'\\b\\w+\\b',ngram_range=(1,2),max_df = 0.8,min_df = 10,stop_words='english',max_features=5000000)\n",
    "# vect.fit(undersampled_docs)\n",
    "# unigram_vect = sklearn.feature_extraction.text.TfidfVectorizer(stop_words='english')\n",
    "# X_train_dtm1 = bigram_vect.fit_transform(undersampled_docs)\n",
    "X_train_dtm = bigram_vect.fit_transform(undersampled_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vect_dev = sklearn.feature_extraction.text.CountVectorizer()\n",
    "# vect_dev.fit(dev_documents)\n",
    "# X_dev_dtm2 = unigram_vect.transform(udev_documents)\n",
    "X_dev_dtm = bigram_vect.transform(udev_documents)\n",
    "# X_dev_dtm = hstack((X_dev_dtm1,X_dev_dtm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.LinearSVC(C=0.8,class_weight='balanced').fit(X_train_dtm, undersampled_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_class =clf.predict(X_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 2 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "predicted_dev_class = clf.predict(X_dev_dtm)\n",
    "print predicted_dev_class\n",
    "for i in range(len(predicted_dev_class)):\n",
    "    if predicted_dev_class[i]==2:\n",
    "        predicted_dev_class[i] = 1\n",
    "    if predicted_dev_class[i]==-2:\n",
    "        predicted_dev_class[i] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without advectives\n",
      "svm\n",
      "train\n",
      "accuracy 0.9788330186720966\n",
      "confusion\n",
      "[[ 37038     11      9      1      9]\n",
      " [    28  37039     37      9      5]\n",
      " [    37     51  81047    295    219]\n",
      " [    85     49    928 143795   5143]\n",
      " [   130     63    451   3147 196209]]\n",
      "macro f 0.9849526061057692\n",
      "micro f 0.9788330186720966\n",
      "weighted f 0.9787917708687245\n",
      "dev\n",
      "accuracy 0.8261828187210161\n",
      "confusion\n",
      "[[ 6687  1642   839]\n",
      " [ 2025  5014  3029]\n",
      " [ 4274  7269 78980]]\n",
      "macro f 0.6442494152866699\n",
      "micro f 0.8261828187210161\n",
      "weighted f 0.8401946571056137\n"
     ]
    }
   ],
   "source": [
    "print \"without advectives\"\n",
    "print \"svm\"\n",
    "print \"train\"\n",
    "measures(undersampled_labels,predicted_class)\n",
    "print \"dev\"\n",
    "measures(udev_labels,predicted_dev_class)\n",
    "f1 = sklearn.metrics.f1_score(udev_labels,predicted_dev_class,average='macro')\n",
    "# with open('../pickles/final_model' + str(f1) + '.pkl', 'w') as f:\n",
    "#     pickle.dump(clf,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../pickles/final_light_model' + str(f1) + '.pkl', 'w') as f:\n",
    "    pickle.dump(clf,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../pickles/final_light_model_dict' + str(f1) + '.pkl', 'w') as f:\n",
    "    pickle.dump(bigram_vect,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(505835, 5000000)\n"
     ]
    }
   ],
   "source": [
    "print np.shape(X_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nb = sklearn.naive_bayes.MultinomialNB()\n",
    "clf_nb.fit(X_train_dtm,undersampled_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_class =clf_nb.predict(X_train_dtm)\n",
    "predicted_dev_class = clf_nb.predict(X_dev_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb\n",
      "train\n",
      "accuracy 0.598655\n",
      "confusion\n",
      "[[     0      0      0      0   8355]\n",
      " [     0      0      0      0   8453]\n",
      " [     0      0     15      1  18525]\n",
      " [     0      0      0     45  44935]\n",
      " [     0      0      0      0 119671]]\n",
      "macro f"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quantumcoder/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.15049439832302508\n",
      "micro f 0.598655\n",
      "weighted f 0.44868140145840124\n",
      "dev\n",
      "accuracy 0.0022139414535482286\n",
      "confusion\n",
      "[[    0    10     5  9153]\n",
      " [    0    69   112  9887]\n",
      " [    0     5   174 90344]\n",
      " [    0     0     0     0]]\n",
      "macro f 0.004356347223829695\n",
      "micro f 0.0022139414535482286\n",
      "weighted f 0.004407320052284517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quantumcoder/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print \"nb\"\n",
    "print \"train\"\n",
    "measures(undersampled_labels,predicted_class)\n",
    "print \"dev\"\n",
    "measures(udev_labels,predicted_dev_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
