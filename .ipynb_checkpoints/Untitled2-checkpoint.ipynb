{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quantumcoder/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/quantumcoder/anaconda2/lib/python2.7/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.cross_validation\n",
    "import sklearn.svm\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.neighbors\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk.sentiment\n",
    "import pickle\n",
    "negate_list = [\"not\",\"never\",\"no\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_documents = []\n",
    "filepath = '../dataset/audio_dev.json' \n",
    "test_summary = []\n",
    "with open(filepath,'r') as fp:  \n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        input_data = (json.loads(line))\n",
    "        test_documents.append(input_data[\"reviewText\"]+input_data[\"summary\"]+input_data[\"summary\"]+input_data[\"summary\"])\n",
    "        line = fp.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleaning2(docs):\n",
    "    new_docs = []\n",
    "    for document in docs:\n",
    "        raw = document.lower()\n",
    "        raw = raw.replace(\"<br /><br />\", \" \")\n",
    "        tokens = tokenizer.tokenize(raw)\n",
    "        stopped_tokens = [token for token in tokens if token not in en_stop]\n",
    "        documentWords = ' '.join(stopped_tokens)\n",
    "        new_docs.append(documentWords)\n",
    "    return new_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def not_clear(tokens):\n",
    "    i =0\n",
    "    for token in tokens:\n",
    "        if token in negate_list or token[-3:]==\"n't\":\n",
    "            if i+1 < len(tokens):\n",
    "                tokens[i+1] =  tokens[i+1] + \"_NEG\"\n",
    "            if i+2 < len(tokens):\n",
    "                tokens[i+2] = tokens[i+2] + \"_NEG\"\n",
    "        i+=1\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def negate(documents):\n",
    "    new_documents = []\n",
    "    for doc in documents:\n",
    "#         doc = doc.lower()\n",
    "        words = doc.split()\n",
    "        new_words = not_clear(words)\n",
    "        newdocument = ' '.join(new_words)\n",
    "        new_documents.append(newdocument)\n",
    "    return new_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../pickles/final_light_model.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "with open('../pickles/final_light_dict_model.pkl', 'rb') as f:\n",
    "    bigram_vect = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utest_docs = negate(test_dcouments)\n",
    "utest_docs = cleaning2(utest_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_dtm = bigram_vect.transform(udev_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_class =clf.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_file = open(name,'w')\n",
    "for i in range(len(predicted_class)):\n",
    "    if predicted_class[i]<0:\n",
    "        output_file.write(\"1\\n\")\n",
    "    elif predicted_class[i]==0:\n",
    "        output_file.write(\"3\\n\")\n",
    "    else:\n",
    "        output_file.write(\"5\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
