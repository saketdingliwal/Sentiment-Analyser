{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.cross_validation\n",
    "import sklearn.svm\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.neighbors\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../dataset/audio_train.json' \n",
    "documents = []\n",
    "class_labels = []\n",
    "\n",
    "documents_1 = []\n",
    "class_labels_1 = []\n",
    "documents_2 = []\n",
    "class_labels_2 = []\n",
    "documents_3 = []\n",
    "class_labels_3 = []\n",
    "summary_1 =[]\n",
    "summary_2 =[]\n",
    "summary_3 =[]\n",
    "\n",
    "with open(filepath,'r') as fp:  \n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        input_data = (json.loads(line))\n",
    "        documents.append(input_data[\"reviewText\"])\n",
    "        class_label = float(input_data[\"overall\"])\n",
    "        if class_label<=2:\n",
    "            class_labels.append(-1)\n",
    "            documents_1.append(input_data[\"reviewText\"] + input_data[\"summary\"] + input_data[\"summary\"]) \n",
    "            summary_1.append(input_data[\"summary\"])\n",
    "            class_labels_1.append(-1)\n",
    "        elif class_label==3:\n",
    "            class_labels.append(0)\n",
    "            documents_2.append(input_data[\"reviewText\"] + input_data[\"summary\"] + input_data[\"summary\"])\n",
    "            summary_2.append(input_data[\"summary\"])\n",
    "            class_labels_2.append(0)\n",
    "        else:\n",
    "            class_labels.append(1)\n",
    "            documents_3.append(input_data[\"reviewText\"] + input_data[\"summary\"] + input_data[\"summary\"])\n",
    "            summary_3.append(input_data[\"summary\"]) \n",
    "            class_labels_3.append(1)\n",
    "        line = fp.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_documents = []\n",
    "dev_labels = []\n",
    "filepath = '../dataset/audio_dev.json' \n",
    "with open(filepath,'r') as fp:  \n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        input_data = (json.loads(line))\n",
    "        dev_documents.append(input_data[\"reviewText\"])\n",
    "        class_label = float(input_data[\"overall\"])\n",
    "        if class_label<=2:\n",
    "            dev_labels.append(-1)\n",
    "        elif class_label==3:\n",
    "            dev_labels.append(0)\n",
    "        else:\n",
    "            dev_labels.append(1)\n",
    "        line = fp.readline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = sklearn.feature_extraction.text.CountVectorizer()\n",
    "clf = sklearn.naive_bayes.MultinomialNB()\n",
    "vect.fit(documents)\n",
    "X_train_dtm = vect.transform(documents)\n",
    "clf.fit(X_train_dtm,class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class =clf.predict(X_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = sklearn.metrics.accuracy_score(class_labels,predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.837742604837\n"
     ]
    }
   ],
   "source": [
    "print train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_dev = sklearn.feature_extraction.text.CountVectorizer()\n",
    "vect_dev.fit(dev_documents)\n",
    "X_dev_dtm = vect.transform(dev_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_dev_class = clf.predict(X_dev_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109759\n"
     ]
    }
   ],
   "source": [
    "print len(predicted_dev_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_accuracy = sklearn.metrics.accuracy_score(dev_labels,predicted_dev_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.830993358176\n"
     ]
    }
   ],
   "source": [
    "print dev_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_confusion = sklearn.metrics.confusion_matrix(dev_labels,predicted_dev_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5141  1277  2750]\n",
      " [ 1569  2600  5899]\n",
      " [ 4039  3016 83468]]\n"
     ]
    }
   ],
   "source": [
    "print dev_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 46168   8952  19066]\n",
      " [ 11076  30096  40477]\n",
      " [ 36546  26357 659336]]\n"
     ]
    }
   ],
   "source": [
    "train_confusion = sklearn.metrics.confusion_matrix(class_labels,predicted_class)\n",
    "print train_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.624683541235\n",
      "0.837742604837\n",
      "0.837143123069\n",
      "0.578948249116\n",
      "0.830993358176\n",
      "0.825072603664\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print f1_score(class_labels,predicted_class,average='macro')\n",
    "print f1_score(class_labels,predicted_class,average='micro')\n",
    "print f1_score(class_labels,predicted_class,average='weighted')\n",
    "print f1_score(dev_labels,predicted_dev_class,average='macro')\n",
    "print f1_score(dev_labels,predicted_dev_class,average='micro')\n",
    "print f1_score(dev_labels,predicted_dev_class,average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 10000  \n",
    "undersampled_docs = documents_1[0:samples] + documents_2[0:samples] + documents_3[0:samples]\n",
    "undersampled_labels = class_labels_1[0:samples] + class_labels_2[0:samples] + class_labels_3[0:samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/saket/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "en_stop = set(stopwords.words('english'))\n",
    "p_stemmer = PorterStemmer()\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for document in undersampled_docs:\n",
    "    raw = document.lower()\n",
    "    raw = raw.replace(\"<br /><br />\", \" \")\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "    stopped_tokens = [token for token in tokens if token not in en_stop]\n",
    "    lemmed_tokens = [wordnet_lemmatizer.lemmatize(token) for token in stopped_tokens]\n",
    "    stemmed_tokens = [p_stemmer.stem(token) for token in lemmed_tokens]\n",
    "    documentWords = ' '.join(stemmed_tokens)\n",
    "    undersampled_docs[i] = documentWords\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = sklearn.feature_extraction.text.CountVectorizer()\n",
    "vect.fit(undersampled_docs)\n",
    "X_train_dtm = vect.transform(undersampled_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='linear').fit(X_train_dtm, undersampled_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class =clf.predict(X_train_dtm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
